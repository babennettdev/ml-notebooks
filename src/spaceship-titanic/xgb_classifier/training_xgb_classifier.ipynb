{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic\n",
    "\n",
    "## Training XGBoost Classifier\n",
    "\n",
    "## Table of Contents\n",
    "- [Spaceship Titanic](#spaceship-titanic)\n",
    "- [Training XGBoost Classifier](#training-xgboost-classifier)\n",
    "- [Table of Contents](#table-of-contents)\n",
    "- [Config](#config)\n",
    "- [Dependencies](#dependencies)\n",
    "- [Data Extraction](#data-extraction)\n",
    "- [Hyper Parameter Tuning](#hyper-parameter-tuning)\n",
    "- [Conclusions](#conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config\n",
    "\n",
    "Set up directory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset_directory = \"../transformed-data\"\n",
    "transformed_training_X_dataset_directory = f\"{transformed_dataset_directory}/train_X.csv\"\n",
    "transformed_training_y_dataset_directory = f\"{transformed_dataset_directory}/train_y.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control hyper parameter tuning.\n",
    "\n",
    ">NOTE: If `do_hyper_parameter_tuning` == `False` include best hyper parameters in `hyper_parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_hyper_parameter_tuning = True\n",
    "hyper_parameters = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install pandas numpy matplotlib seaborn xgboost scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(transformed_training_X_dataset_directory)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(transformed_training_y_dataset_directory)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=13\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide `hyper_parameters_to_search` to find best possible combination of hyper parameters.\n",
    "\n",
    ">NOTE: Longer ranges will require longer processing times. Once an optimal set of hyper parameters is found, set `do_hyper_parameter_tuning` to `False` and `hyper_parameters` to `hyper_parameter_grid_search.best_params_` in the [Config](#config) section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_hyper_parameter_tuning == True:\n",
    "    \n",
    "    xgb_classifier = XGBClassifier()\n",
    "\n",
    "    hyper_parameters_to_search = {\n",
    "    'n_estimators': range(5,15),\n",
    "    'max_depth': range(1, 15),\n",
    "    'learning_rate': [.1, .2, .3, .4, .5, .6],\n",
    "    'colsample_bytree': [.7, .8, .9, 1],\n",
    "    'eval_metric': ['error', 'logloss'],\n",
    "    'use_label_encoder': [False]\n",
    "    }\n",
    "\n",
    "    hyper_parameter_grid_search = GridSearchCV(estimator = xgb_classifier, param_grid = hyper_parameters_to_search,\n",
    "    cv = 3, n_jobs = 1, verbose = 0, return_train_score=True)\n",
    "\n",
    "    hyper_parameter_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(hyper_parameter_grid_search.best_params_)\n",
    "    hyper_parameter_grid_search.score(X_test,y_test)\n",
    "else:\n",
    "    print(\"Hyper parameter tuning skipped...\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
